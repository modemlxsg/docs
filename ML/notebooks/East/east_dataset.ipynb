{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from dataset import custom_dataset\n",
    "from model import EAST\n",
    "from loss import Loss\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vertices(lines):\n",
    "    '''extract vertices info from txt lines\n",
    "    Input:\n",
    "        lines   : list of string info\n",
    "    Output:\n",
    "        vertices: vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        labels  : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
    "    '''\n",
    "    labels = []\n",
    "    vertices = []\n",
    "    for line in lines:\n",
    "        vertices.append(list(map(int,line.rstrip('\\n').lstrip('\\ufeff').split(',')[:8])))\n",
    "        label = 0 if '###' in line else 1\n",
    "        labels.append(label)\n",
    "    return np.array(vertices), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_height(img, vertices, ratio=0.2):\n",
    "    '''adjust height of image to aug data(高度0.8-1.2)\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        ratio       : height changes in [0.8, 1.2]\n",
    "    Output:\n",
    "        img         : adjusted PIL Image\n",
    "        new_vertices: adjusted vertices\n",
    "    '''\n",
    "    ratio_h = 1 + ratio * (np.random.rand() * 2 - 1)\n",
    "    old_h = img.height\n",
    "    new_h = int(np.around(old_h * ratio_h))\n",
    "    img = img.resize((img.width, new_h), Image.BILINEAR)\n",
    "    \n",
    "    new_vertices = vertices.copy()\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * (new_h / old_h)\n",
    "    return img, new_vertices\n",
    "\n",
    "def crop_img(img, vertices, labels, length):\n",
    "    '''crop img patches to obtain batch and augment\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        labels      : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
    "        length      : length of cropped image region\n",
    "    Output:\n",
    "        region      : cropped image region\n",
    "        new_vertices: new vertices in cropped region\n",
    "    '''\n",
    "    h, w = img.height, img.width\n",
    "    # confirm the shortest side of image >= length\n",
    "    if h >= w and w < length:\n",
    "        img = img.resize((length, int(h * length / w)), Image.BILINEAR)\n",
    "    elif h < w and h < length:\n",
    "        img = img.resize((int(w * length / h), length), Image.BILINEAR)\n",
    "    ratio_w = img.width / w\n",
    "    ratio_h = img.height / h\n",
    "    assert(ratio_w >= 1 and ratio_h >= 1)\n",
    "\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[0,2,4,6]] = vertices[:,[0,2,4,6]] * ratio_w\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * ratio_h\n",
    "\n",
    "    # find random position\n",
    "    remain_h = img.height - length\n",
    "    remain_w = img.width - length\n",
    "    flag = True\n",
    "    cnt = 0\n",
    "    while flag and cnt < 1000:\n",
    "        cnt += 1\n",
    "        start_w = int(np.random.rand() * remain_w)\n",
    "        start_h = int(np.random.rand() * remain_h)\n",
    "        flag = is_cross_text([start_w, start_h], length, new_vertices[labels==1,:])\n",
    "    box = (start_w, start_h, start_w + length, start_h + length)\n",
    "    region = img.crop(box)\n",
    "    if new_vertices.size == 0:\n",
    "        return region, new_vertices    \n",
    "    \n",
    "    new_vertices[:,[0,2,4,6]] -= start_w\n",
    "    new_vertices[:,[1,3,5,7]] -= start_h\n",
    "    return region, new_vertices\n",
    "\n",
    "def rotate_img(img, vertices, angle_range=10):\n",
    "    '''rotate image [-10, 10] degree to aug data\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        angle_range : rotate range\n",
    "    Output:\n",
    "        img         : rotated PIL Image\n",
    "        new_vertices: rotated vertices\n",
    "    '''\n",
    "    center_x = (img.width - 1) / 2\n",
    "    center_y = (img.height - 1) / 2\n",
    "    angle = angle_range * (np.random.rand() * 2 - 1)\n",
    "    img = img.rotate(angle, Image.BILINEAR)\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    for i, vertice in enumerate(vertices):\n",
    "        new_vertices[i,:] = rotate_vertices(vertice, -angle / 180 * math.pi, np.array([[center_x],[center_y]]))\n",
    "    return img, new_vertices\n",
    "\n",
    "def rotate_vertices(vertices, theta, anchor=None):\n",
    "    '''rotate vertices around anchor\n",
    "    Input:    \n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        theta   : angle in radian measure\n",
    "        anchor  : fixed position during rotation\n",
    "    Output:\n",
    "        rotated vertices <numpy.ndarray, (8,)>\n",
    "    '''\n",
    "    v = vertices.reshape((4,2)).T\n",
    "    if anchor is None:\n",
    "        anchor = v[:,:1]\n",
    "    rotate_mat = get_rotate_mat(theta)\n",
    "    res = np.dot(rotate_mat, v - anchor)\n",
    "    return (res + anchor).T.reshape(-1)\n",
    "\n",
    "def get_rotate_mat(theta):\n",
    "    '''positive theta value means rotate clockwise'''\n",
    "    return np.array([[math.cos(theta), -math.sin(theta)], [math.sin(theta), math.cos(theta)]])\n",
    "\n",
    "def is_cross_text(start_loc, length, vertices):\n",
    "    '''check if the crop image crosses text regions\n",
    "    Input:\n",
    "        start_loc: left-top position\n",
    "        length   : length of crop image\n",
    "        vertices : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "    Output:\n",
    "        True if crop image crosses text region\n",
    "    '''\n",
    "    if vertices.size == 0:\n",
    "        return False\n",
    "    start_w, start_h = start_loc\n",
    "    a = np.array([start_w, start_h, start_w + length, start_h, \\\n",
    "          start_w + length, start_h + length, start_w, start_h + length]).reshape((4,2))\n",
    "    p1 = Polygon(a).convex_hull\n",
    "    for vertice in vertices:\n",
    "        p2 = Polygon(vertice.reshape((4,2))).convex_hull\n",
    "        inter = p1.intersection(p2).area\n",
    "        if 0.01 <= inter / p2.area <= 0.99: \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_all_pixels(rotate_mat, anchor_x, anchor_y, length):\n",
    "    '''get rotated locations of all pixels for next stages\n",
    "    Input:\n",
    "        rotate_mat: rotatation matrix\n",
    "        anchor_x  : fixed x position\n",
    "        anchor_y  : fixed y position\n",
    "        length    : length of image\n",
    "    Output:\n",
    "        rotated_x : rotated x positions <numpy.ndarray, (length,length)>\n",
    "        rotated_y : rotated y positions <numpy.ndarray, (length,length)>\n",
    "    '''\n",
    "    x = np.arange(length)\n",
    "    y = np.arange(length)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    x_lin = x.reshape((1, x.size))\n",
    "    y_lin = y.reshape((1, x.size))\n",
    "    coord_mat = np.concatenate((x_lin, y_lin), 0)\n",
    "    rotated_coord = np.dot(rotate_mat, coord_mat - np.array([[anchor_x], [anchor_y]])) + \\\n",
    "                                                   np.array([[anchor_x], [anchor_y]])\n",
    "    rotated_x = rotated_coord[0, :].reshape(x.shape)\n",
    "    rotated_y = rotated_coord[1, :].reshape(y.shape)\n",
    "    return rotated_x, rotated_y\n",
    "\n",
    "def get_boundary(vertices):\n",
    "    '''get the tight boundary around given vertices\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        the boundary\n",
    "    '''\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    x_min = min(x1, x2, x3, x4)\n",
    "    x_max = max(x1, x2, x3, x4)\n",
    "    y_min = min(y1, y2, y3, y4)\n",
    "    y_max = max(y1, y2, y3, y4)\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "def cal_error(vertices):\n",
    "    '''default orientation is x1y1 : left-top, x2y2 : right-top, x3y3 : right-bot, x4y4 : left-bot\n",
    "    calculate the difference between the vertices orientation and default orientation\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        err     : difference measure\n",
    "    '''\n",
    "    x_min, x_max, y_min, y_max = get_boundary(vertices)\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    err = cal_distance(x1, y1, x_min, y_min) + cal_distance(x2, y2, x_max, y_min) + \\\n",
    "          cal_distance(x3, y3, x_max, y_max) + cal_distance(x4, y4, x_min, y_max)\n",
    "    return err    \n",
    "\n",
    "def find_min_rect_angle(vertices):\n",
    "    '''find the best angle to rotate poly and obtain min rectangle\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        the best angle <radian measure>\n",
    "    '''\n",
    "    angle_interval = 1\n",
    "    angle_list = list(range(-90, 90, angle_interval))\n",
    "    area_list = []\n",
    "    for theta in angle_list: \n",
    "        rotated = rotate_vertices(vertices, theta / 180 * math.pi)\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = rotated\n",
    "        temp_area = (max(x1, x2, x3, x4) - min(x1, x2, x3, x4)) * \\\n",
    "                    (max(y1, y2, y3, y4) - min(y1, y2, y3, y4))\n",
    "        area_list.append(temp_area)\n",
    "    \n",
    "    sorted_area_index = sorted(list(range(len(area_list))), key=lambda k : area_list[k])\n",
    "    min_error = float('inf')\n",
    "    best_index = -1\n",
    "    rank_num = 10\n",
    "    # find the best angle with correct orientation\n",
    "    for index in sorted_area_index[:rank_num]:\n",
    "        rotated = rotate_vertices(vertices, angle_list[index] / 180 * math.pi)\n",
    "        temp_error = cal_error(rotated)\n",
    "        if temp_error < min_error:\n",
    "            min_error = temp_error\n",
    "            best_index = index\n",
    "    return angle_list[best_index] / 180 * math.pi\n",
    "\n",
    "def move_points(vertices, index1, index2, r, coef):\n",
    "    '''move the two points to shrink edge\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        index1  : offset of point1\n",
    "        index2  : offset of point2\n",
    "        r       : [r1, r2, r3, r4] in paper\n",
    "        coef    : shrink ratio in paper\n",
    "    Output:\n",
    "        vertices: vertices where one edge has been shinked\n",
    "    '''\n",
    "    index1 = index1 % 4\n",
    "    index2 = index2 % 4\n",
    "    x1_index = index1 * 2 + 0\n",
    "    y1_index = index1 * 2 + 1\n",
    "    x2_index = index2 * 2 + 0\n",
    "    y2_index = index2 * 2 + 1\n",
    "    \n",
    "    r1 = r[index1]\n",
    "    r2 = r[index2]\n",
    "    length_x = vertices[x1_index] - vertices[x2_index]\n",
    "    length_y = vertices[y1_index] - vertices[y2_index]\n",
    "    length = cal_distance(vertices[x1_index], vertices[y1_index], vertices[x2_index], vertices[y2_index])\n",
    "    if length > 1:    \n",
    "        ratio = (r1 * coef) / length\n",
    "        vertices[x1_index] += ratio * (-length_x) \n",
    "        vertices[y1_index] += ratio * (-length_y) \n",
    "        ratio = (r2 * coef) / length\n",
    "        vertices[x2_index] += ratio * length_x \n",
    "        vertices[y2_index] += ratio * length_y\n",
    "    return vertices    \n",
    "\n",
    "def cal_distance(x1, y1, x2, y2):\n",
    "    '''calculate the Euclidean distance'''\n",
    "    return math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "def shrink_poly(vertices, coef=0.3):\n",
    "    '''shrink the text region\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        coef    : shrink ratio in paper\n",
    "    Output:\n",
    "        v       : vertices of shrinked text region <numpy.ndarray, (8,)>\n",
    "    '''\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    r1 = min(cal_distance(x1,y1,x2,y2), cal_distance(x1,y1,x4,y4))\n",
    "    r2 = min(cal_distance(x2,y2,x1,y1), cal_distance(x2,y2,x3,y3))\n",
    "    r3 = min(cal_distance(x3,y3,x2,y2), cal_distance(x3,y3,x4,y4))\n",
    "    r4 = min(cal_distance(x4,y4,x1,y1), cal_distance(x4,y4,x3,y3))\n",
    "    r = [r1, r2, r3, r4]\n",
    "\n",
    "    # obtain offset to perform move_points() automatically\n",
    "    if cal_distance(x1,y1,x2,y2) + cal_distance(x3,y3,x4,y4) > \\\n",
    "       cal_distance(x2,y2,x3,y3) + cal_distance(x1,y1,x4,y4):\n",
    "        offset = 0 # two longer edges are (x1y1-x2y2) & (x3y3-x4y4)\n",
    "    else:\n",
    "        offset = 1 # two longer edges are (x2y2-x3y3) & (x4y4-x1y1)\n",
    "\n",
    "    v = vertices.copy()\n",
    "    v = move_points(v, 0 + offset, 1 + offset, r, coef)\n",
    "    v = move_points(v, 2 + offset, 3 + offset, r, coef)\n",
    "    v = move_points(v, 1 + offset, 2 + offset, r, coef)\n",
    "    v = move_points(v, 3 + offset, 4 + offset, r, coef)\n",
    "    return v\n",
    "\n",
    "def get_score_geo(img, vertices, labels, scale, length):\n",
    "    '''generate score gt and geometry gt\n",
    "    Input:\n",
    "        img     : PIL Image\n",
    "        vertices: vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        labels  : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
    "        scale   : feature map / image\n",
    "        length  : image length\n",
    "    Output:\n",
    "        score gt, geo gt, ignored\n",
    "    '''\n",
    "    score_map   = np.zeros((int(img.height * scale), int(img.width * scale), 1), np.float32)\n",
    "    geo_map     = np.zeros((int(img.height * scale), int(img.width * scale), 5), np.float32)\n",
    "    ignored_map = np.zeros((int(img.height * scale), int(img.width * scale), 1), np.float32)\n",
    "    \n",
    "    index = np.arange(0, length, int(1/scale))\n",
    "    index_x, index_y = np.meshgrid(index, index)\n",
    "    ignored_polys = []\n",
    "    polys = []\n",
    "    \n",
    "    for i, vertice in enumerate(vertices):\n",
    "        if labels[i] == 0:\n",
    "            ignored_polys.append(np.around(scale * vertice.reshape((4,2))).astype(np.int32))\n",
    "            continue        \n",
    "        \n",
    "        poly = np.around(scale * shrink_poly(vertice).reshape((4,2))).astype(np.int32) # scaled & shrinked\n",
    "        polys.append(poly)\n",
    "        print(vertices)\n",
    "        print(poly)\n",
    "        \n",
    "        temp_mask = np.zeros(score_map.shape[:-1], np.float32)\n",
    "        cv2.fillPoly(temp_mask, [poly], 1)\n",
    "        \n",
    "        theta = find_min_rect_angle(vertice)\n",
    "        rotate_mat = get_rotate_mat(theta)\n",
    "        \n",
    "        rotated_vertices = rotate_vertices(vertice, theta)\n",
    "        x_min, x_max, y_min, y_max = get_boundary(rotated_vertices)\n",
    "        rotated_x, rotated_y = rotate_all_pixels(rotate_mat, vertice[0], vertice[1], length)\n",
    "    \n",
    "        d1 = rotated_y - y_min\n",
    "        d1[d1<0] = 0\n",
    "        d2 = y_max - rotated_y\n",
    "        d2[d2<0] = 0\n",
    "        d3 = rotated_x - x_min\n",
    "        d3[d3<0] = 0\n",
    "        d4 = x_max - rotated_x\n",
    "        d4[d4<0] = 0\n",
    "        geo_map[:,:,0] += d1[index_y, index_x] * temp_mask\n",
    "        geo_map[:,:,1] += d2[index_y, index_x] * temp_mask\n",
    "        geo_map[:,:,2] += d3[index_y, index_x] * temp_mask\n",
    "        geo_map[:,:,3] += d4[index_y, index_x] * temp_mask\n",
    "        geo_map[:,:,4] += theta * temp_mask\n",
    "    \n",
    "    cv2.fillPoly(ignored_map, ignored_polys, 1)\n",
    "    cv2.fillPoly(score_map, polys, 1)\n",
    "    return torch.Tensor(score_map).permute(2,0,1), \\\n",
    "           torch.Tensor(geo_map).permute(2,0,1), \\\n",
    "           torch.Tensor(ignored_map).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(data.Dataset):\n",
    "    def __init__(self, img_path, gt_path, scale=0.25, length=512):\n",
    "        super(custom_dataset, self).__init__()\n",
    "        self.img_files = [os.path.join(img_path, img_file) for img_file in sorted(os.listdir(img_path))]\n",
    "        self.gt_files  = [os.path.join(gt_path, gt_file) for gt_file in sorted(os.listdir(gt_path))]\n",
    "        self.scale = scale\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with open(self.gt_files[index], 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        vertices, labels = extract_vertices(lines) # 提取坐标、标签\n",
    "        img = Image.open(self.img_files[index])\n",
    "        img, vertices = adjust_height(img, vertices) # 调整高度\n",
    "        img, vertices = rotate_img(img, vertices) # 旋转图形\n",
    "        img, vertices = crop_img(img, vertices, labels, self.length) # 剪裁\n",
    "        \n",
    "        transform = transforms.Compose([transforms.ColorJitter(0.5, 0.5, 0.5, 0.25), \\\n",
    "                                            transforms.ToTensor(), \\\n",
    "                                            transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
    "        \n",
    "        score_map, geo_map, ignored_map = get_score_geo(img, vertices, labels, self.scale, self.length)\n",
    "        return transform(img), score_map, geo_map, ignored_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = \"H:\\dataset\\ICDAR2015\\ch4_training_images\"\n",
    "train_gt_path =  \"H:\\dataset\\ICDAR2015\\ch4_training_localization_transcription_gt\"\n",
    "trainset = custom_dataset(train_img_path, train_gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, score_map, geo_map, ignored_map = trainset.__getitem__(1)\n",
    "img.shape\n",
    "score_map.shape\n",
    "geo_map.shape\n",
    "ignored_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
