{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_ori = keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                     fname='I:/ML_DATASET/flower_photos',\n",
    "                     untar=True)\n",
    "print(data_root_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_root = pathlib.Path(data_root_ori)\n",
    "\n",
    "for item in data_root.iterdir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "image_count = len(all_image_paths)\n",
    "\n",
    "random.shuffle(all_image_paths)\n",
    "print(image_count)\n",
    "all_image_paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "for n in range(3):\n",
    "  image_path = random.choice(all_image_paths)\n",
    "  display.display(display.Image(image_path))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 确定每张图片的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出可用的标签\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个标签分配索引\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个列表，包含每个文件的标签索引\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载和格式化图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = all_image_paths[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw = tf.io.read_file(img_path)\n",
    "print(repr(img_raw)[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将它解码为图像 tensor（张量）\n",
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据你的模型调整其大小\n",
    "img_final = tf.image.resize(img_tensor, [192, 192])\n",
    "img_final = img_final/255.0\n",
    "print(img_final.shape)\n",
    "print(img_final.numpy().min())\n",
    "print(img_final.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这些包装在一个简单的函数里，以备后用\n",
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = all_image_paths[0]\n",
    "label = all_image_labels[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path))\n",
    "plt.grid(False)\n",
    "plt.title(label_names[label].title())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个 tf.data.Dataset\n",
    "\n",
    "构建 tf.data.Dataset 最简单的方法就是使用 **from_tensor_slices** 方法。\n",
    "将字符串数组切片，得到一个字符串数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "print(path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在创建一个新的数据集，通过在路径数据集上映射 preprocess_image 来动态加载和格式化图片\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, image in enumerate(image_ds.take(4)):\n",
    "  plt.subplot(2,2,n+1)\n",
    "  plt.imshow(image)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一个(图片, 标签)对数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用同样的 from_tensor_slices 方法你可以创建一个标签数据集：\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_ds.take(10):\n",
    "  print(label_names[label.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于这些数据集顺序相同，你可以将他们打包在一起得到一个(图片, 标签)对数据集：\n",
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "print(image_label_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意：当你拥有形似 all_image_labels 和 all_image_paths 的数组，tf.data.dataset.Dataset.zip 的替代方法是将这对数组切片。\n",
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "\n",
    "# 元组被解压缩到映射函数的位置参数中\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "image_label_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练的基本方法\n",
    "要使用此数据集训练模型，你将会想要数据：\n",
    "\n",
    "被充分打乱。\n",
    "被分割为 batch。\n",
    "永远重复。\n",
    "尽快提供 batch。\n",
    "使用 tf.data api 可以轻松添加这些功能。\n",
    "\n",
    "这里有一些注意事项：\n",
    "\n",
    "顺序很重要。\n",
    "\n",
    "在 .repeat 之后 .shuffle，会在 epoch 之间打乱数据（当有些数据出现两次的时候，其他数据还没有出现过）。\n",
    "\n",
    "在 .batch 之后 .shuffle，会打乱 batch 的顺序，但是不会在 batch 之间打乱数据。\n",
    "\n",
    "你在完全打乱中使用和数据集大小一样的 buffer_size（缓冲区大小）。较大的缓冲区大小提供更好的随机化，但使用更多的内存，直到超过数据集大小。\n",
    "\n",
    "在从随机缓冲区中拉取任何元素前，要先填满它。所以当你的 Dataset（数据集）启动的时候一个大的 buffer_size（缓冲区大小）可能会引起延迟。\n",
    "\n",
    "在随机缓冲区完全为空之前，被打乱的数据集不会报告数据集的结尾。Dataset（数据集）由 .repeat 重新启动，导致需要再次等待随机缓冲区被填满。\n",
    "\n",
    "最后一点可以通过使用 tf.data.Dataset.apply 方法和融合过的 tf.data.experimental.shuffle_and_repeat 函数来解决:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# 设置一个和数据集大小一致的 shuffle buffer size（随机缓冲区大小）以保证数据被充分打乱。\n",
    "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 传递数据集至模型\n",
    "\n",
    "从 tf.keras.applications 取得 MobileNet v2 副本。\n",
    "\n",
    "该模型副本会被用于一个简单的迁移学习例子。\n",
    "\n",
    "设置 MobileNet 的权重为不可训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_192_no_top.h5\n",
      "9412608/9406464 [==============================] - 73s 8us/step\n"
     ]
    }
   ],
   "source": [
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3), include_top=False)\n",
    "mobile_net.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该模型期望它的输出被标准化至 [-1,1] 范围内：\n",
    "# 在你将输出传递给 MobilNet 模型之前，你需要将其范围从 [0,1] 转化为 [-1,1]：\n",
    "def change_range(image,label):\n",
    "  return 2*image-1, label\n",
    "\n",
    "keras_ds = ds.map(change_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 6, 6, 1280)\n"
     ]
    }
   ],
   "source": [
    "# MobileNet 为每张图片的特征返回一个 6x6 的空间网格。传递一个 batch 的图片给它，查看结果：\n",
    "# 数据集可能需要几秒来启动，因为要填满其随机缓冲区。\n",
    "image_batch, label_batch = next(iter(keras_ds))\n",
    "\n",
    "feature_map_batch = mobile_net(image_batch)\n",
    "print(feature_map_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个包装了 MobileNet 的模型并在 tf.keras.layers.Dense 输出层之前使用 tf.keras.layers.GlobalAveragePooling2D 来平均那些空间向量\n",
    "model = tf.keras.Sequential([\n",
    "  mobile_net,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(label_names), activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min logit: 0.007987428\n",
      "max logit: 0.87735933\n",
      "\n",
      "Shape: (32, 5)\n"
     ]
    }
   ],
   "source": [
    "logit_batch = model(image_batch).numpy()\n",
    "\n",
    "print(\"min logit:\", logit_batch.min())\n",
    "print(\"max logit:\", logit_batch.max())\n",
    "print()\n",
    "\n",
    "print(\"Shape:\", logit_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_192 (Model) (None, 6, 6, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 6405      \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出于演示目的每一个 epoch 中你将只运行 3 step，但一般来说在传递给 model.fit() 之前你会指定 step 的真实数量，如下所示：\n",
    "steps_per_epoch=tf.math.ceil(len(all_image_paths)/BATCH_SIZE).numpy()\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3 steps\n",
      "3/3 [==============================] - 20s 7s/step - loss: 1.8143 - accuracy: 0.2292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20531d800b8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=1, steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能\n",
    "\n",
    "这部分只是展示一些可能帮助提升性能的简单技巧。深入指南，请看：输入 pipeline（管道）的性能  \n",
    "上面使用的简单 pipeline（管道）在每个 epoch 中单独读取每个文件。在本地使用 CPU 训练时这个方法是可行的，但是可能不足以进行 GPU 训练并且完全不适合任何形式的分布式训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "default_timeit_steps = 2*steps_per_epoch+1\n",
    "\n",
    "def timeit(ds, steps=default_timeit_steps):\n",
    "  overall_start = time.time()\n",
    "  # 在开始计时之前\n",
    "  # 取得单个 batch 来填充 pipeline（管道）（填充随机缓冲区）\n",
    "  it = iter(ds.take(steps+1))\n",
    "  next(it)\n",
    "\n",
    "  start = time.time()\n",
    "  for i,(images,labels) in enumerate(it):\n",
    "    if i%10 == 0:\n",
    "      print('.',end='')\n",
    "  print()\n",
    "  end = time.time()\n",
    "\n",
    "  duration = end-start\n",
    "  print(\"{} batches: {} s\".format(steps, duration))\n",
    "  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))\n",
    "  print(\"Total time: {}s\".format(end-overall_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当前数据集的性能是：\n",
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 18.955130338668823 s\n",
      "389.97358 Images/s\n",
      "Total time: 27.31833529472351s\n"
     ]
    }
   ],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缓存\n",
    "\n",
    "使用 tf.data.Dataset.cache 在 epoch 之间轻松缓存计算结果。这是非常高效的，特别是当内存能容纳全部数据时。  \n",
    "\n",
    "在被预处理之后（解码和调整大小），图片在此被缓存了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = image_label_ds.cache()\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 1.609093189239502 s\n",
      "4593.89180 Images/s\n",
      "Total time: 9.948296070098877s\n"
     ]
    }
   ],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用内存缓存的一个缺点是必须在每次运行时重建缓存，这使得每次启动数据集时有相同的启动延迟：\n",
    "# 如果内存不够容纳数据，使用一个缓存文件：\n",
    "ds = image_label_ds.cache(filename='./cache.tf-data')\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 20.538777828216553 s\n",
      "359.90457 Images/s\n",
      "Total time: 55.31582283973694s\n"
     ]
    }
   ],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 20.08068823814392 s\n",
      "368.11487 Images/s\n",
      "Total time: 29.128297805786133s\n"
     ]
    }
   ],
   "source": [
    "# 这个缓存文件也有可快速重启数据集而无需重建缓存的优点。注意第二次快了多少：\n",
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## TFRecord 文件\n",
    "\n",
    "TFRecord文件是一种用来存储一串二进制blob的简单格式。  \n",
    "通过将多个示例打包进同一个文件内，TensorFlow 能够一次性读取多个示例，当使用一个远程存储服务，如 GCS 时，这对性能来说尤其重要。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始图片数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，从原始图片数据中构建出一个 TFRecord 文件：\n",
    "image_ds = tf.data.Dataset.from_tensor_slices(all_image_paths).map(tf.io.read_file)\n",
    "tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n",
    "tfrec.write(image_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接着，构建一个从 TFRecord 文件读取的数据集，并使用你之前定义的 preprocess_image 函数对图像进行解码/重新格式化：\n",
    "image_ds = tf.data.TFRecordDataset('images.tfrec').map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 192, 192, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 压缩该数据集和你之前定义的标签数据集以得到期望的 (图片,标签) 对：\n",
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds=ds.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 16.85435199737549 s\n",
      "438.58109 Images/s\n",
      "Total time: 24.021242141723633s\n"
     ]
    }
   ],
   "source": [
    "timeit(ds) # 这比 缓存 版本慢，因为你还没有缓存预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 序列化的 Tensor（张量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (192, 192, 3), types: tf.float32>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要为 TFRecord 文件省去一些预处理过程，首先像之前一样制作一个处理过的图片数据集：\n",
    "paths_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = paths_ds.map(load_and_preprocess_image)\n",
    "image_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在你有一个 tensor（张量）数据集，而不是一个 .jpeg 字符串数据集。\n",
    "# 要将此序列化至一个 TFRecord 文件你首先将该 tensor（张量）数据集转化为一个字符串数据集：\n",
    "ds = image_ds.map(tf.io.serialize_tensor)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\n",
    "tfrec.write(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: (192, 192, 3), types: tf.float32>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有了被缓存的预处理，就能从 TFrecord 文件高效地加载数据——只需记得在使用它之前反序列化：\n",
    "ds = tf.data.TFRecordDataset('images.tfrec')\n",
    "\n",
    "def parse(x):\n",
    "  result = tf.io.parse_tensor(x, out_type=tf.float32)\n",
    "  result = tf.reshape(result, [192, 192, 3])\n",
    "  return result\n",
    "\n",
    "ds = ds.map(parse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((None, 192, 192, 3), (None,)), (None,)), types: ((tf.float32, tf.int64), tf.int64)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.zip((ds, label_ds))\n",
    "ds = ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds=ds.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "231.0 batches: 41.00366282463074 s\n",
      "180.27658 Images/s\n",
      "Total time: 72.92915940284729s\n"
     ]
    }
   ],
   "source": [
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
