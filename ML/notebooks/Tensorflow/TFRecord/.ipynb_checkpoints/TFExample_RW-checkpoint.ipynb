{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./ICDAR15_Demo\"\n",
    "\n",
    "imgs = glob.glob(os.path.join(data_dir,'*.jpg'))\n",
    "gts = glob.glob(os.path.join(data_dir,'*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img_raw = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img_raw)\n",
    "    return img\n",
    "\n",
    "img_ds = tf.data.Dataset.from_tensor_slices(imgs)\n",
    "img_ds = img_ds.map(read_img)\n",
    "\n",
    "\n",
    "gt_ds = []\n",
    "for path in gts:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        line = [line.lstrip('\\ufeff').rstrip('\\n').split(',')[:8] for line in lines]\n",
    "        gt_ds.append(line)\n",
    "\n",
    "gt_ds = tf.ragged.constant(gt_ds)\n",
    "gt_ds = tf.data.Dataset.from_tensor_slices(gt_ds)\n",
    "gt_ds = gt_ds.map(lambda x:tf.strings.to_number(x.to_tensor(),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = img_ds.map(tf.io.serialize_tensor)\n",
    "gt_ds = gt_ds.map(tf.io.serialize_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = tf.data.Dataset.zip((img_ds, gt_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = tf.data.experimental.TFRecordWriter('ds.tfrecord')\n",
    "# writer.write(img_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(img_raw, gt):\n",
    "    \n",
    "    feature = {\n",
    "        'img_raw' : _bytes_feature(img_raw),\n",
    "        'gt' : _bytes_feature(gt)\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "def create_example_map(img_raw, gt):\n",
    "    \n",
    "    tf_string = tf.py_function(create_example, inp=(img_raw, gt), Tout=tf.string)\n",
    "    \n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = data_ds.map(create_example_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(data_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {gt: (), img_raw: ()}, types: {gt: tf.string, img_raw: tf.string}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_description = {\n",
    "    'img_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'gt': tf.io.FixedLenFeature([], tf.string, default_value='')\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 8), dtype=float32, numpy=\n",
       "array([[377., 117., 463., 117., 465., 130., 378., 130.],\n",
       "       [493., 115., 519., 115., 519., 131., 493., 131.],\n",
       "       [374., 155., 409., 155., 409., 170., 374., 170.],\n",
       "       [492., 151., 551., 151., 551., 170., 492., 170.],\n",
       "       [376., 198., 422., 198., 422., 212., 376., 212.],\n",
       "       [494., 190., 539., 189., 539., 205., 494., 206.],\n",
       "       [374.,   1., 494.,   0., 492.,  85., 372.,  86.]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(720, 1280, 3), dtype=uint8, numpy=\n",
       "array([[[191, 152, 170],\n",
       "        [185, 146, 164],\n",
       "        [184, 145, 163],\n",
       "        ...,\n",
       "        [142, 115, 134],\n",
       "        [142, 114, 136],\n",
       "        [143, 115, 138]],\n",
       "\n",
       "       [[190, 151, 169],\n",
       "        [184, 148, 162],\n",
       "        [184, 145, 163],\n",
       "        ...,\n",
       "        [142, 115, 132],\n",
       "        [142, 114, 136],\n",
       "        [143, 115, 138]],\n",
       "\n",
       "       [[190, 154, 168],\n",
       "        [183, 150, 161],\n",
       "        [183, 147, 161],\n",
       "        ...,\n",
       "        [142, 115, 132],\n",
       "        [142, 114, 136],\n",
       "        [143, 115, 137]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79,  69,  57],\n",
       "        [ 81,  71,  59],\n",
       "        [ 85,  75,  63],\n",
       "        ...,\n",
       "        [ 33,  28,  25],\n",
       "        [ 31,  26,  23],\n",
       "        [ 30,  25,  22]],\n",
       "\n",
       "       [[ 78,  69,  52],\n",
       "        [ 80,  71,  54],\n",
       "        [ 85,  76,  61],\n",
       "        ...,\n",
       "        [ 35,  27,  24],\n",
       "        [ 31,  26,  22],\n",
       "        [ 30,  25,  21]],\n",
       "\n",
       "       [[ 77,  69,  50],\n",
       "        [ 80,  72,  53],\n",
       "        [ 84,  75,  58],\n",
       "        ...,\n",
       "        [ 35,  27,  24],\n",
       "        [ 31,  26,  22],\n",
       "        [ 30,  25,  21]]], dtype=uint8)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in parsed_dataset.take(1):\n",
    "    st = item.get('gt')\n",
    "    tf.io.parse_tensor(st, tf.float32)\n",
    "    \n",
    "    it = item.get('img_raw')\n",
    "    tf.io.parse_tensor(it, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
