{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EmNxHqcQSne"
   },
   "source": [
    "## 第五章  PyTorch常用工具模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klBbuM8bQSni"
   },
   "source": [
    "在训练神经网络过程中，需要用到很多工具，其中最重要的三部分是：数据、可视化和GPU加速。本章主要介绍Pytorch在这几方面的工具模块，合理使用这些工具能够极大地提高编码效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yuETqIdOQSni"
   },
   "source": [
    "### 5.1 数据处理\n",
    "\n",
    "在解决深度学习问题的过程中，往往需要花费大量的精力去处理数据，包括图像、文本、语音或其它二进制数据等。数据的处理对训练神经网络来说十分重要，良好的数据处理不仅会加速模型训练，更会提高模型效果。考虑到这点，PyTorch提供了几个高效便捷的工具，以便使用者进行数据处理或增强等操作，同时可通过并行化加速数据加载。\n",
    "\n",
    "#### 5.1.1 数据加载\n",
    "\n",
    "在PyTorch中，数据加载可通过自定义的数据集对象。数据集对象被抽象为`Dataset`类，实现自定义的数据集需要继承Dataset，并实现两个Python魔法方法：\n",
    "- `__getitem__`：返回一条数据，或一个样本。`obj[index]`等价于`obj.__getitem__(index)`\n",
    "- `__len__`：返回样本的数量。`len(obj)`等价于`obj.__len__()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxveoAPqQSnk"
   },
   "source": [
    "这里我们以Kaggle经典挑战赛[\"Dogs vs. Cat\"](https://www.kaggle.com/c/dogs-vs-cats/)的数据为例，来详细讲解如何处理数据。\"Dogs vs. Cats\"是一个分类问题，判断一张图片是狗还是猫，其所有图片都存放在一个文件夹下，根据文件名的前缀判断是狗还是猫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSo4kxGfQSnl",
    "outputId": "dc5f323d-40d0-4bc1-937f-795eaa11ea3d"
   },
   "outputs": [],
   "source": [
    "%env LS_COLORS = None \n",
    "!tree --charset ascii  data/dogcat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDs-EyZnQSnu"
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0x-W-NZQSnz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import  Image\n",
    "import numpy as np\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        imgs = os.listdir(root)\n",
    "        # 所有图片的绝对路径\n",
    "        # 这里不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root, img) for img in imgs]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        # dog->1， cat->0\n",
    "        label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        pil_img = Image.open(img_path)\n",
    "        array = np.asarray(pil_img)\n",
    "        data = t.from_numpy(array)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9oW2jlcQSn2",
    "outputId": "0e941015-587c-45e2-874b-d6433f6a5969",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = DogCat('./data/dogcat/')\n",
    "img, label = dataset[0] # 相当于调用dataset.__getitem__(0)\n",
    "for img, label in dataset:\n",
    "    print(img.size(), img.float().mean(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4FuYJ1zQSn8"
   },
   "source": [
    "通过上面的代码，我们学习了如何自定义自己的数据集，并可以依次获取。但这里返回的数据不适合实际使用，因其具有如下两方面问题：\n",
    "- 返回样本的形状不一，因每张图片的大小不一样，这对于需要取batch训练的神经网络来说很不友好\n",
    "- 返回样本的数值较大，未归一化至[-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pri4FT73QSn_"
   },
   "source": [
    "针对上述问题，PyTorch提供了torchvision[^1]。它是一个视觉工具包，提供了很多视觉图像处理的工具，其中`transforms`模块提供了对PIL `Image`对象和`Tensor`对象的常用操作。\n",
    "\n",
    "对PIL Image的操作包括：\n",
    "- `Scale`：调整图片尺寸，长宽比保持不变\n",
    "- `CenterCrop`、`RandomCrop`、`RandomResizedCrop`： 裁剪图片\n",
    "- `Pad`：填充\n",
    "- `ToTensor`：将PIL Image对象转成Tensor，会自动将[0, 255]归一化至[0, 1]\n",
    "\n",
    "对Tensor的操作包括：\n",
    "- Normalize：标准化，即减均值，除以标准差\n",
    "- ToPILImage：将Tensor转为PIL Image对象\n",
    "\n",
    "如果要对图片进行多个操作，可通过`Compose`函数将这些操作拼接起来，类似于`nn.Sequential`。注意，这些操作定义后是以函数的形式存在，真正使用时需调用它的`__call__`方法，这点类似于`nn.Module`。例如要将图片调整为$224\\times 224$，首先应构建这个操作`trans = Resize((224, 224))`，然后调用`trans(img)`。下面我们就用transforms的这些操作来优化上面实现的dataset。\n",
    "[^1]: https://github.com/pytorch/vision/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8u-PCkyeQSoB",
    "outputId": "2d247ad3-73eb-48b2-c5a9-7bedd79d2073"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import  Image\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(224), # 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "    T.CenterCrop(224), # 从图片中间切出224*224的图片\n",
    "    T.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "    T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) # 标准化至[-1, 1]，规定均值和标准差\n",
    "])\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        imgs = os.listdir(root)\n",
    "        self.imgs = [os.path.join(root, img) for img in imgs]\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        label = 0 if 'dog' in img_path.split('/')[-1] else 1\n",
    "        data = Image.open(img_path)\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "dataset = DogCat('./data/dogcat/', transforms=transform)\n",
    "img, label = dataset[0]\n",
    "for img, label in dataset:\n",
    "    print(img.size(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi2LO-kaQSoH"
   },
   "source": [
    "除了上述操作之外，transforms还可通过`Lambda`封装自定义的转换策略。例如想对PIL Image进行随机旋转，则可写成这样`trans=T.Lambda(lambda img: img.rotate(random()*360))`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bERXyyX2QSoJ"
   },
   "source": [
    "torchvision已经预先实现了常用的Dataset，包括前面使用过的CIFAR-10，以及ImageNet、COCO、MNIST、LSUN等数据集，可通过诸如`torchvision.datasets.CIFAR10`来调用，具体使用方法请参看官方文档[^1]。在这里介绍一个会经常使用到的Dataset——`ImageFolder`，它的实现和上述的`DogCat`很相似。`ImageFolder`假设所有的文件按文件夹保存，每个文件夹下存储同一个类别的图片，文件夹名为类名，其构造函数如下：\n",
    "```\n",
    "ImageFolder(root, transform=None, target_transform=None, loader=default_loader)\n",
    "```\n",
    "它主要有四个参数：\n",
    "- `root`：在root指定的路径下寻找图片\n",
    "- `transform`：对PIL Image进行的转换操作，transform的输入是使用loader读取图片的返回对象\n",
    "- `target_transform`：对label的转换\n",
    "- `loader`：给定路径后如何读取图片，默认读取为RGB格式的PIL Image对象\n",
    "\n",
    "label是按照文件夹名顺序排序后存成字典，即{类名:类序号(从0开始)}，一般来说最好直接将文件夹命名为从0开始的数字，这样会和ImageFolder实际的label一致，如果不是这种命名规范，建议看看`self.class_to_idx`属性以了解label和文件夹名的映射关系。\n",
    "\n",
    "[^1]: http://pytorch.org/docs/master/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSCqyRGlQSoK",
    "outputId": "06b62b5a-d359-437a-d2df-90bfb4371cfe"
   },
   "outputs": [],
   "source": [
    "!tree --charset ASCII  data/dogcat_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gp2_2UgbQSoQ"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "dataset = ImageFolder('data/dogcat_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKTHUW2LQSoU",
    "outputId": "aa787500-947f-4b6f-929e-363539879619"
   },
   "outputs": [],
   "source": [
    "# cat文件夹的图片对应label 0，dog对应1\n",
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYjtvDUBQSog",
    "outputId": "042749a1-90d4-4854-9a9a-47a09cb41960",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 所有图片的路径和对应的label\n",
    "dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnXIsAqQSol",
    "outputId": "e1198ee0-5b0b-4cf1-eb81-8a4d8cfb2646",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 没有任何的transform，所以返回的还是PIL Image对象\n",
    "dataset[0][1] # 第一维是第几张图，第二维为1返回label\n",
    "dataset[0][0] # 为0返回图片数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U94Z_XsOQSoo"
   },
   "outputs": [],
   "source": [
    "# 加上transform\n",
    "normalize = T.Normalize(mean=[0.4, 0.4, 0.4], std=[0.2, 0.2, 0.2])\n",
    "transform  = T.Compose([\n",
    "         T.RandomResizedCrop(224),\n",
    "         T.RandomHorizontalFlip(),\n",
    "         T.ToTensor(),\n",
    "         normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zz1tWfIFQSos"
   },
   "outputs": [],
   "source": [
    "dataset = ImageFolder('data/dogcat_2/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwPzZTM7QSou",
    "outputId": "830ac5b3-715b-41b7-866a-c48600c0db82"
   },
   "outputs": [],
   "source": [
    "# 深度学习中图片数据一般保存成CxHxW，即通道数x图片高x图片宽\n",
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNMckYc1QSoz",
    "outputId": "6fa05e2f-17be-4522-ded4-2227ccc5bcca"
   },
   "outputs": [],
   "source": [
    "to_img = T.ToPILImage()\n",
    "# 0.2和0.4是标准差和均值的近似\n",
    "to_img(dataset[0][0]*0.2+0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3nguADBQSo3"
   },
   "source": [
    "`Dataset`只负责数据的抽象，一次调用`__getitem__`只返回一个样本。前面提到过，在训练神经网络时，最好是对一个batch的数据进行操作，同时还需要对数据进行shuffle和并行加速等。对此，PyTorch提供了`DataLoader`帮助我们实现这些功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5KAcDOuQSo5"
   },
   "source": [
    "DataLoader的函数定义如下： \n",
    "`DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False)`\n",
    "\n",
    "- dataset：加载的数据集(Dataset对象)\n",
    "- batch_size：batch size\n",
    "- shuffle:：是否将数据打乱\n",
    "- sampler： 样本抽样，后续会详细介绍\n",
    "- num_workers：使用多进程加载的进程数，0代表不使用多进程\n",
    "- collate_fn： 如何将多个样本数据拼接成一个batch，一般使用默认的拼接方式即可\n",
    "- pin_memory：是否将数据保存在pin memory区，pin memory中的数据转到GPU会快一些\n",
    "- drop_last：dataset中的数据个数可能不是batch_size的整数倍，drop_last为True会将多出来不足一个batch的数据丢弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQGBV2PaQSo7"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qo8x_RJdQSo9"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITmn78OMQSpB",
    "outputId": "dbd84276-a697-4582-f9c4-52ae6f4a1cdd"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "imgs, labels = next(dataiter)\n",
    "imgs.size() # batch_size, channel, height, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8kOwJ-FQSpG"
   },
   "source": [
    "dataloader是一个可迭代的对象，意味着我们可以像使用迭代器一样使用它，例如：\n",
    "```python\n",
    "for batch_datas, batch_labels in dataloader:\n",
    "    train()\n",
    "```\n",
    "或\n",
    "```\n",
    "dataiter = iter(dataloader)\n",
    "batch_datas, batch_labesl = next(dataiter)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rs-4vwglQSpH"
   },
   "source": [
    "在数据处理中，有时会出现某个样本无法读取等问题，比如某张图片损坏。这时在`__getitem__`函数中将出现异常，此时最好的解决方案即是将出错的样本剔除。如果实在是遇到这种情况无法处理，则可以返回None对象，然后在`Dataloader`中实现自定义的`collate_fn`，将空对象过滤掉。但要注意，在这种情况下dataloader返回的batch数目会少于batch_size。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFSVmwkmQSpI"
   },
   "outputs": [],
   "source": [
    "class NewDogCat(DogCat): # 继承前面实现的DogCat数据集\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # 调用父类的获取函数，即 DogCat.__getitem__(self, index)\n",
    "            return super(NewDogCat,self).__getitem__(index)\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate # 导入默认的拼接方式\n",
    "def my_collate_fn(batch):\n",
    "    '''\n",
    "    batch中每个元素形如(data, label)\n",
    "    '''\n",
    "    # 过滤为None的数据\n",
    "    batch = list(filter(lambda x:x[0] is not None, batch))\n",
    "    if len(batch) == 0: return t.Tensor()\n",
    "    return default_collate(batch) # 用默认方式拼接过滤后的batch数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Biu1be72QSpM"
   },
   "outputs": [],
   "source": [
    "dataset = NewDogCat('data/dogcat_wrong/', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfYuVkJJQSpP",
    "outputId": "e03d03d6-985b-42bb-e5ae-31c2def09cee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zcgyv9XFQSpT",
    "outputId": "9ca7b7c4-b336-4944-8af2-895cc000ba95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, 2, collate_fn=my_collate_fn, num_workers=1,shuffle=True)\n",
    "for batch_datas, batch_labels in dataloader:\n",
    "    print(batch_datas.size(),batch_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8_jONguQSpW"
   },
   "source": [
    "来看一下上述batch_size的大小。其中第2个的batch_size为1，这是因为有一张图片损坏，导致其无法正常返回。而最后1个的batch_size也为1，这是因为共有9张（包括损坏的文件）图片，无法整除2（batch_size），因此最后一个batch的数据会少于batch_szie，可通过指定`drop_last=True`来丢弃最后一个不足batch_size的batch。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHiAsfGJQSpX"
   },
   "source": [
    "对于诸如样本损坏或数据集加载异常等情况，还可以通过其它方式解决。例如但凡遇到异常情况，就随机取一张图片代替：\n",
    "```python\n",
    "class NewDogCat(DogCat):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super(NewDogCat, self).__getitem__(index)\n",
    "        except:\n",
    "            new_index = random.randint(0, len(self)-1)\n",
    "            return self[new_index]\n",
    "```\n",
    "相比较丢弃异常图片而言，这种做法会更好一些，因为它能保证每个batch的数目仍是batch_size。但在大多数情况下，最好的方式还是对数据进行彻底清洗。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpQcN6FLQSpZ"
   },
   "source": [
    "DataLoader里面并没有太多的魔法方法，它封装了Python的标准库`multiprocessing`，使其能够实现多进程加速。在此提几点关于Dataset和DataLoader使用方面的建议：\n",
    "1. 高负载的操作放在`__getitem__`中，如加载图片等。\n",
    "2. dataset中应尽量只包含只读对象，避免修改任何可变对象，利用多线程进行操作。\n",
    "\n",
    "第一点是因为多进程会并行的调用`__getitem__`函数，将负载高的放在`__getitem__`函数中能够实现并行加速。\n",
    "第二点是因为dataloader使用多进程加载，如果在`Dataset`实现中使用了可变对象，可能会有意想不到的冲突。在多线程/多进程中，修改一个可变对象，需要加锁，但是dataloader的设计使得其很难加锁（在实际使用中也应尽量避免锁的存在），因此最好避免在dataset中修改可变对象。例如下面就是一个不好的例子，在多进程处理中`self.num`可能与预期不符，这种问题不会报错，因此难以发现。如果一定要修改可变对象，建议使用Python标准库`Queue`中的相关数据结构。\n",
    "\n",
    "```python\n",
    "class BadDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.datas = range(100)\n",
    "        self.num = 0 # 取数据的次数\n",
    "    def __getitem__(self, index):\n",
    "        self.num += 1\n",
    "        return self.datas[index]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_LwBwFjwQSpb"
   },
   "source": [
    "使用Python `multiprocessing`库的另一个问题是，在使用多进程时，如果主程序异常终止（比如用Ctrl+C强行退出），相应的数据加载进程可能无法正常退出。这时你可能会发现程序已经退出了，但GPU显存和内存依旧被占用着，或通过`top`、`ps aux`依旧能够看到已经退出的程序，这时就需要手动强行杀掉进程。建议使用如下命令：\n",
    "\n",
    "```\n",
    "ps x | grep <cmdline> | awk '{print $1}' | xargs kill\n",
    "```\n",
    "\n",
    "- `ps x`：获取当前用户的所有进程\n",
    "- `grep <cmdline>`：找到已经停止的PyTorch程序的进程，例如你是通过python train.py启动的，那你就需要写`grep 'python train.py'`\n",
    "- `awk '{print $1}'`：获取进程的pid\n",
    "- `xargs kill`：杀掉进程，根据需要可能要写成`xargs kill -9`强制杀掉进程\n",
    "\n",
    "在执行这句命令之前，建议先打印确认一下是否会误杀其它进程\n",
    "```\n",
    "ps x | grep <cmdline> | ps x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvT8dortQSpd"
   },
   "source": [
    "PyTorch中还单独提供了一个`sampler`模块，用来对数据进行采样。常用的有随机采样器：`RandomSampler`，当dataloader的`shuffle`参数为True时，系统会自动调用这个采样器，实现打乱数据。默认的是采用`SequentialSampler`，它会按顺序一个一个进行采样。这里介绍另外一个很有用的采样方法：\n",
    "`WeightedRandomSampler`，它会根据每个样本的权重选取数据，在样本比例不均衡的问题中，可用它来进行重采样。\n",
    "\n",
    "构建`WeightedRandomSampler`时需提供两个参数：每个样本的权重`weights`、共选取的样本总数`num_samples`，以及一个可选参数`replacement`。权重越大的样本被选中的概率越大，待选取的样本数目一般小于全部的样本数目。`replacement`用于指定是否可以重复选取某一个样本，默认为True，即允许在一个epoch中重复采样某一个数据。如果设为False，则当某一类的样本被全部选取完，但其样本数目仍未达到num_samples时，sampler将不会再从该类中选择数据，此时可能导致`weights`参数失效。下面举例说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRaKhO8yQSpe",
    "outputId": "348f0404-eaf9-4f3e-aea1-480207ebeabf"
   },
   "outputs": [],
   "source": [
    "dataset = DogCat('data/dogcat/', transforms=transform)\n",
    "\n",
    "# 狗的图片被取出的概率是猫的概率的两倍\n",
    "# 两类图片被取出的概率与weights的绝对大小无关，只和比值有关\n",
    "weights = [2 if label == 1 else 1 for data, label in dataset]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWyYj8dXQSpi",
    "outputId": "2287ae32-f5c8-4e49-96f6-cc619dc2e199"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import  WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(weights,\\\n",
    "                                num_samples=9,\\\n",
    "                                replacement=True)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=3,\n",
    "                        sampler=sampler)\n",
    "for datas, labels in dataloader:\n",
    "    print(labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XH4RxCyoQSpm"
   },
   "source": [
    "可见猫狗样本比例约为1:2，另外一共只有8个样本，但是却返回了9个，说明肯定有被重复返回的，这就是replacement参数的作用，下面将replacement设为False试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUVstVbzQSpn",
    "outputId": "4881c371-1b2f-4571-9e9f-a58b36abb698",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(weights, 8, replacement=False)\n",
    "dataloader = DataLoader(dataset, batch_size=4, sampler=sampler)\n",
    "for datas, labels in dataloader:\n",
    "    print(labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJuHANqRQSpr"
   },
   "source": [
    "在这种情况下，num_samples等于dataset的样本总数，为了不重复选取，sampler会将每个样本都返回，这样就失去weight参数的意义了。\n",
    "\n",
    "从上面的例子可见sampler在样本采样中的作用：如果指定了sampler，shuffle将不再生效，并且sampler.num_samples会覆盖dataset的实际大小，即一个epoch返回的图片总数取决于`sampler.num_samples`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9wGzGCFQSps"
   },
   "source": [
    "### 5.2 计算机视觉工具包：torchvision\n",
    "计算机视觉是深度学习中最重要的一类应用，为了方便研究者使用，PyTorch团队专门开发了一个视觉工具包`torchvion`，这个包独立于PyTorch，需通过`pip instal torchvision`安装。在之前的例子中我们已经见识到了它的部分功能，这里再做一个系统性的介绍。torchvision主要包含三部分：\n",
    "\n",
    "- models：提供深度学习中各种经典网络的网络结构以及预训练好的模型，包括`AlexNet`、VGG系列、ResNet系列、Inception系列等。\n",
    "- datasets： 提供常用的数据集加载，设计上都是继承`torhc.utils.data.Dataset`，主要包括`MNIST`、`CIFAR10/100`、`ImageNet`、`COCO`等。\n",
    "- transforms：提供常用的数据预处理操作，主要包括对Tensor以及PIL Image对象的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZlQtuKeQSpt",
    "outputId": "34a051b6-332a-48cd-c5ce-4176959544d6"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "# 加载预训练好的模型，如果不存在会进行下载\n",
    "# 预训练好的模型保存在 ~/.torch/models/下面\n",
    "resnet34 = models.squeezenet1_1(pretrained=True, num_classes=1000)\n",
    "\n",
    "# 修改最后的全连接层为10分类问题（默认是ImageNet上的1000分类）\n",
    "resnet34.fc=nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEUOUBzTQSpx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "# 指定数据集路径为data，如果数据集不存在则进行下载\n",
    "# 通过train=False获取测试集\n",
    "dataset = datasets.MNIST('data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GApbSaqZQSp4"
   },
   "source": [
    "Transforms中涵盖了大部分对Tensor和PIL Image的常用处理，这些已在上文提到，这里就不再详细介绍。需要注意的是转换分为两步，第一步：构建转换操作，例如`transf = transforms.Normalize(mean=x, std=y)`，第二步：执行转换操作，例如`output = transf(input)`。另外还可将多个处理操作用Compose拼接起来，形成一个处理转换流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeabINW3QSp6",
    "outputId": "a4524b45-f5e0-4421-e990-aecaef346bbb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms \n",
    "to_pil = transforms.ToPILImage()\n",
    "to_pil(t.randn(3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfoxlUZcQSp9"
   },
   "source": [
    "torchvision还提供了两个常用的函数。一个是`make_grid`，它能将多张图片拼接成一个网格中；另一个是`save_img`，它能将Tensor保存成图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCOalTCOQSp-",
    "outputId": "e9cb8f9c-1b96-43a3-b137-09e9d1d99667"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6ngXqxmQSqC",
    "outputId": "3a7b8b12-ed33-455b-e573-456d6c83c93b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n",
    "from torchvision.utils import make_grid, save_image\n",
    "dataiter = iter(dataloader)\n",
    "img = make_grid(next(dataiter)[0], 4) # 拼成4*4网格图片，且会转成３通道\n",
    "to_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQvVzII7QSqG",
    "outputId": "df7404c6-db3c-4682-98c5-6beb83929ea5"
   },
   "outputs": [],
   "source": [
    "save_image(img, 'a.png')\n",
    "Image.open('a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZW2HV71QSqQ",
    "toc-hr-collapsed": false
   },
   "source": [
    "### 5.3 可视化工具\n",
    "在训练神经网络时，我们希望能更直观地了解训练情况，包括损失曲线、输入图片、输出图片、卷积核的参数分布等信息。这些信息能帮助我们更好地监督网络的训练过程，并为参数优化提供方向和依据。最简单的办法就是打印输出，但其只能打印数值信息，不够直观，同时无法查看分布、图片、声音等。在本节，我们将介绍两个深度学习中常用的可视化工具：Tensorboard和Visdom。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXXPpPwJQSqT"
   },
   "source": [
    "#### 5.3.1 Tensorboard\n",
    "\n",
    "Tensorboard最初是作为TensorFlow的可视化工具迅速流行开来。作为和TensorFlow深度集成的工具，Tensorboard能够展现你的TensorFlow网络计算图，绘制图像生成的定量指标图以及附加数据。但同时Tensorboard也是一个相对独立的工具，只要用户保存的数据遵循相应的格式，tensorboard就能读取这些数据并进行可视化。这里我们将主要介绍如何在PyTorch中使用tensorboardX[^1]进行训练损失的可视化。\n",
    "TensorboardX是将Tensorboard的功能抽取出来，使得非TensorFlow用户也能使用它进行可视化，几乎支持原生TensorBoard的全部功能。\n",
    "\n",
    "![图1；tensorboard界面](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/tensorboard.png?raw=1)\n",
    "[^1]:https://github.com/lanpa/tensorboardX\n",
    "\n",
    "tensorboard的安装主要分为以下两步：\n",
    "- 安装TensorFlow：如果电脑中已经安装完TensorFlow可以跳过这一步，如果电脑中尚未安装，建议安装CPU-Only的版本，具体安装教程参见TensorFlow官网[^1]，或使用pip直接安装，推荐使用清华的软件源[^2]。\n",
    "- 安装tensorboard: `pip install tensorboard`\n",
    "- 安装tensorboardX：可通过`pip install tensorboardX`命令直接安装。\n",
    "\n",
    "tensorboardX的使用非常简单。首先用如下命令启动tensorboard：\n",
    "```bash\n",
    "tensorboard --logdir <your/running/dir> --port <your_bind_port>\n",
    "```\n",
    "\n",
    "下面举例说明tensorboardX的使用。\n",
    "\n",
    "[^1]: https://www.tensorflow.org/install/\n",
    "[^2]: https://mirrors.tuna.tsinghua.edu.cn/help/tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k536SK8yQSqV"
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y8902L5QSqZ"
   },
   "outputs": [],
   "source": [
    "# 构建logger对象，logdir用来指定log文件的保存路径\n",
    "# flush_secs用来指定刷新同步间隔\n",
    "logger = SummaryWriter(log_dir='experimient_cnn', flush_secs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sCEyE5TQSqb"
   },
   "outputs": [],
   "source": [
    "for ii in range(100):\n",
    "    logger.add_scalar('data/loss', 10-ii**0.5)\n",
    "    logger.add_scalar('data/accuracy', ii**0.5/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjxOKQjoQSqe"
   },
   "source": [
    "打开浏览器输入`http://localhost:6006`（其中6006应改成你的tensorboard所绑定的端口），即可看到如图2所示的结果。\n",
    "![图2: tensorboard可视化结果](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/tensorboard2.png?raw=1)\n",
    "左侧的Horizontal Axis下有三个选项，分别是：\n",
    "- Step：根据步长来记录，log_value时如果有步长，则将其作为x轴坐标描点画线。\n",
    "- Relative：用前后相对顺序描点画线，可认为logger自己维护了一个`step`属性，每调用一次log_value就自动加１。\n",
    "- Wall：按时间排序描点画线。\n",
    "\n",
    "左侧的Smoothing条可以左右拖动，用来调节平滑的幅度。点击右上角的刷新按钮可立即刷新结果，默认是每30s自动刷新数据。可见tensorboard_logger的使用十分简单，但它只能统计简单的数值信息，不支持其它功能。\n",
    "\n",
    "感兴趣的读者可以从github项目主页获取更多信息，本节将把更多的内容留给另一个可视化工具：Visdom。\n",
    "[^4]: https://github.com/lanpa/tensorboard-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpH7ECR7QSqh"
   },
   "source": [
    "#### 5.3.2 Visdom\n",
    "Visdom[^5]是Facebook专门为PyTorch开发的一款可视化工具，其开源于2017年3月。Visdom十分轻量级，但却支持非常丰富的功能，能胜任大多数的科学运算可视化任务。其可视化界面如图3所示。\n",
    "\n",
    "![图3: visdom界面](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom.png?raw=1)\n",
    "[^5]: https://github.com/facebookresearch/visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gizUDEZQSql"
   },
   "source": [
    "Visdom可以创造、组织和共享多种数据的可视化，包括数值、图像、文本，甚至是视频，其支持PyTorch、Torch及Numpy。用户可通过编程组织可视化空间，或通过用户接口为生动数据打造仪表板，检查实验结果或调试代码。\n",
    "\n",
    "Visdom中有两个重要概念：\n",
    "- env：环境。不同环境的可视化结果相互隔离，互不影响，在使用时如果不指定env，默认使用`main`。不同用户、不同程序一般使用不同的env。\n",
    "- pane：窗格。窗格可用于可视化图像、数值或打印文本等，其可以拖动、缩放、保存和关闭。一个程序中可使用同一个env中的不同pane，每个pane可视化或记录某一信息。\n",
    "\n",
    "如图4所示，当前env共有两个pane，一个用于打印log，另一个用于记录损失函数的变化。点击clear按钮可以清空当前env的所有pane，点击save按钮可将当前env保存成json文件，保存路径位于`~/.visdom/`目录下。也可修改env的名字后点击fork，保存当前env的状态至更名后的env。\n",
    "![图4：visdom_env](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom_env_pane.png?raw=1)\n",
    "\n",
    "Visdom的安装可通过命令`pip install visdom`。安装完成后，需通过`python -m visdom.server`命令启动visdom服务，或通过`nohup python -m visdom.server &`命令将服务放至后台运行。Visdom服务是一个web server服务，默认绑定8097端口，客户端与服务器间通过tornado进行非阻塞交互。\n",
    "\n",
    "Visdom的使用有两点需要注意的地方：\n",
    "- 需手动指定保存env，可在web界面点击save按钮或在程序中调用save方法，否则visdom服务重启后，env等信息会丢失。\n",
    "- 客户端与服务器之间的交互采用tornado异步框架，可视化操作不会阻塞当前程序，网络异常也不会导致程序退出。\n",
    "\n",
    "Visdom以Plotly为基础，支持丰富的可视化操作，下面举例说明一些最常用的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLDizE01QSqo"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# 启动visdom服务器\n",
    "# nohup python -m visdom.server &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdaBYE5RQSqs"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OcWCQknQSqu",
    "outputId": "8e945128-60c4-4efc-e0f2-dcb2b619d252"
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "# 新建一个连接客户端\n",
    "# 指定env = u'test1'，默认端口为8097，host是‘localhost'\n",
    "vis = visdom.Visdom(env=u'test1',use_incoming_socket=False)\n",
    "\n",
    "x = t.arange(1, 30, 0.01)\n",
    "y = t.sin(x)\n",
    "vis.line(X=x, Y=y, win='sinx', opts={'title': 'y=sin(x)'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OE0s2r98QSq1"
   },
   "source": [
    "输出的结果如图5所示。\n",
    "![图5： visdom的输出](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom_sinx.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvqtypInQSq4"
   },
   "source": [
    "下面逐一分析这几行代码：\n",
    "- vis = visdom.Visdom(env=u'test1')，用于构建一个客户端，客户端除指定env之外，还可以指定host、port等参数。\n",
    "- vis作为一个客户端对象，可以使用常见的画图函数，包括：\n",
    "\n",
    "    - line：类似Matlab中的`plot`操作，用于记录某些标量的变化，如损失、准确率等\n",
    "    - image：可视化图片，可以是输入的图片，也可以是GAN生成的图片，还可以是卷积核的信息\n",
    "    - text：用于记录日志等文字信息，支持html格式\n",
    "    - histgram：可视化分布，主要是查看数据、参数的分布\n",
    "    - scatter：绘制散点图\n",
    "    - bar：绘制柱状图\n",
    "    - pie：绘制饼状图\n",
    "    - 更多操作可参考visdom的github主页\n",
    "    \n",
    "这里主要介绍深度学习中常见的line、image和text操作。\n",
    "\n",
    "Visdom同时支持PyTorch的tensor和Numpy的ndarray两种数据结构，但不支持Python的int、float等类型，因此每次传入时都需先将数据转成ndarray或tensor。上述操作的参数一般不同，但有两个参数是绝大多数操作都具备的：\n",
    "- win：用于指定pane的名字，如果不指定，visdom将自动分配一个新的pane。如果两次操作指定的win名字一样，新的操作将覆盖当前pane的内容，因此建议每次操作都重新指定win。\n",
    "- opts：选项，接收一个字典，常见的option包括`title`、`xlabel`、`ylabel`、`width`等，主要用于设置pane的显示格式。\n",
    "\n",
    "之前提到过，每次操作都会覆盖之前的数值，但往往我们在训练网络的过程中需不断更新数值，如损失值等，这时就需要指定参数`update='append'`来避免覆盖之前的数值。而除了使用update参数以外，还可以使用`vis.updateTrace`方法来更新图，但`updateTrace`不仅能在指定pane上新增一个和已有数据相互独立的Trace，还能像`update='append'`那样在同一条trace上追加数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSDxUsewQSq5",
    "outputId": "46b2074c-2284-4b16-f70f-3ccd895cd472"
   },
   "outputs": [],
   "source": [
    "# append 追加数据\n",
    "for ii in range(0, 10):\n",
    "    # y = x\n",
    "    x = t.Tensor([ii])\n",
    "    y = x\n",
    "    vis.line(X=x, Y=y, win='polynomial', update='append' if ii>0 else None)\n",
    "    \n",
    "# updateTrace 新增一条线\n",
    "x = t.arange(0, 9, 0.1)\n",
    "y = (x ** 2) / 9\n",
    "vis.line(X=x, Y=y, win='polynomial', name='this is a new Trace',update='new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RziuwSvqQSq8"
   },
   "source": [
    "打开浏览器，输入`http://localhost:8097`，可以看到如图6所示的结果。\n",
    "![图6 ：append和updateTrace可视化效果 ](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom_update.svg?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFTqpqn3QSq8"
   },
   "source": [
    "image的画图功能可分为如下两类：\n",
    "- `image`接收一个二维或三维向量，$H\\times W$或$3 \\times H\\times W$，前者是黑白图像，后者是彩色图像。\n",
    "- `images`接收一个四维向量$N\\times C\\times H\\times W$，$C$可以是1或3，分别代表黑白和彩色图像。可实现类似torchvision中make_grid的功能，将多张图片拼接在一起。`images`也可以接收一个二维或三维的向量，此时它所实现的功能与image一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SETcT0N3QSq-",
    "outputId": "2d3ff3a4-9d90-4065-f860-bd20cbfa3672"
   },
   "outputs": [],
   "source": [
    "# 可视化一个随机的黑白图片\n",
    "vis.image(t.randn(64, 64).numpy())\n",
    "\n",
    "# 随机可视化一张彩色图片\n",
    "vis.image(t.randn(3, 64, 64).numpy(), win='random2')\n",
    "\n",
    "# 可视化36张随机的彩色图片，每一行6张\n",
    "vis.images(t.randn(36, 3, 64, 64).numpy(), nrow=6, win='random3', opts={'title':'random_imgs'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6D3CgRqrQSrB"
   },
   "source": [
    "其中images的可视化输出如图7所示。\n",
    "![图7： images可视化输出](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom_images.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Y9K8-EQSrB"
   },
   "source": [
    "`vis.text`用于可视化文本，支持所有的html标签，同时也遵循着html的语法标准。例如，换行需使用`<br>`标签，`\\r\\n`无法实现换行。下面举例说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugIg16T7QSrC",
    "outputId": "5687f4ae-adca-47a3-ab66-eb2f647ef575"
   },
   "outputs": [],
   "source": [
    "vis.text(u'''<h1>Hello Visdom</h1><br>Visdom是Facebook专门为<b>PyTorch</b>开发的一个可视化工具，\n",
    "         在内部使用了很久，在2017年3月份开源了它。\n",
    "         \n",
    "         Visdom十分轻量级，但是却有十分强大的功能，支持几乎所有的科学运算可视化任务''',\n",
    "         win='visdom',\n",
    "         opts={'title': u'visdom简介' }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXGLBCTtQSrH"
   },
   "source": [
    "![图8：text的可视化输出](https://github.com/chenyuntc/pytorch-book/blob/master/chapter05-utilities/imgs/visdom_text.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK8qdEB5QSrI"
   },
   "source": [
    "### 5.4 使用GPU加速：cuda\n",
    "这部分内容在前面介绍Tensor、Module时大都提到过，这里将做一个总结，并深入介绍相关应用。\n",
    "\n",
    "在PyTorch中以下数据结构分为CPU和GPU两个版本：\n",
    "- Tensor\n",
    "- nn.Module（包括常用的layer、loss function，以及容器Sequential等）\n",
    "\n",
    "它们都带有一个`.cuda`方法，调用此方法即可将其转为对应的GPU对象。注意，`tensor.cuda`会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor还在原来的设备上（CPU）。而`module.cuda`则会将所有的数据都迁移至GPU，并返回自己。所以`module = module.cuda()`和`module.cuda()`所起的作用一致。\n",
    "\n",
    "nn.Module在GPU与CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。`nn.Module`的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Parameter本质上也是tensor(Tensor的子类)。\n",
    "\n",
    "下面将举例说明，这部分代码需要你具有两块GPU设备。\n",
    "\n",
    "P.S. 为什么将数据转移至GPU的方法叫做`.cuda`而不是`.gpu`，就像将数据转移至CPU调用的方法是`.cpu`？这是因为GPU的编程接口采用CUDA，而目前并不是所有的GPU都支持CUDA，只有部分Nvidia的GPU才支持。PyTorch未来可能会支持AMD的GPU，而AMD GPU的编程接口采用OpenCL，因此PyTorch还预留着`.cl`方法，用于以后支持AMD等的GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVtOtEfoQSrJ",
    "outputId": "58a60f9a-1482-4c0b-e151-b2f7a4014d65"
   },
   "outputs": [],
   "source": [
    "tensor = t.Tensor(3, 4)\n",
    "# 返回一个新的tensor，保存在第1块GPU上，但原来的tensor并没有改变\n",
    "tensor.cuda(0)\n",
    "tensor.is_cuda # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUZ2N3OXQSrM",
    "outputId": "815ad805-a614-41a1-960d-bee379ee1e80"
   },
   "outputs": [],
   "source": [
    "# 不指定所使用的GPU设备，将默认使用第1块GPU\n",
    "tensor = tensor.cuda()\n",
    "tensor.is_cuda # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMd7uZp7QSrP",
    "outputId": "ad8b6cb0-9afe-4472-f771-34a0c9b907c5"
   },
   "outputs": [],
   "source": [
    "module = nn.Linear(3, 4)\n",
    "module.cuda(device = 1)\n",
    "module.weight.is_cuda # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqqItqoVQSrT"
   },
   "outputs": [],
   "source": [
    "class VeryBigModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VeryBigModule, self).__init__()\n",
    "        self.GiantParameter1 = t.nn.Parameter(t.randn(100000, 20000)).cuda(0)\n",
    "        self.GiantParameter2 = t.nn.Parameter(t.randn(20000, 100000)).cuda(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.GiantParameter1.mm(x.cuda(0))\n",
    "        x = self.GiantParameter2.mm(x.cuda(1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWTCQy3hQSrs"
   },
   "source": [
    "上面最后一部分中，两个Parameter所占用的内存空间都非常大，大概是8个G，如果将这两个都同时放在一块GPU上几乎会将显存占满，无法再进行任何其它运算。此时可通过这种方式将不同的计算分布到不同的GPU中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2_rEDa_QSrt"
   },
   "source": [
    "关于使用GPU的一些建议：\n",
    "- GPU运算很快，但对于很小的运算量来说，并不能体现出它的优势，因此对于一些简单的操作可直接利用CPU完成\n",
    "- 数据在CPU和GPU之间，以及GPU与GPU之间的传递会比较耗时，应当尽量避免\n",
    "- 在进行低精度的计算时，可以考虑`HalfTensor`，它相比于`FloatTensor`能节省一半的显存，但需千万注意数值溢出的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wefsgcK9QSrv"
   },
   "source": [
    "另外这里需要专门提一下，大部分的损失函数也都属于`nn.Moudle`，但在使用GPU时，很多时候我们都忘记使用它的`.cuda`方法，这在大多数情况下不会报错，因为损失函数本身没有可学习的参数（learnable parameters）。但在某些情况下会出现问题，为了保险起见同时也为了代码更规范，应记得调用`criterion.cuda`。下面举例说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yj8rVbNlQSrv",
    "outputId": "901e7090-4b29-4c97-c767-a6aede9a5487"
   },
   "outputs": [],
   "source": [
    "# 交叉熵损失函数，带权重\n",
    "criterion = t.nn.CrossEntropyLoss(weight=t.Tensor([1, 3]))\n",
    "input = t.randn(4, 2).cuda()\n",
    "target = t.Tensor([1, 0, 0, 1]).long().cuda()\n",
    "\n",
    "# 下面这行会报错，因weight未被转移至GPU\n",
    "# loss = criterion(input, target)\n",
    "\n",
    "# 这行则不会报错\n",
    "criterion.cuda()\n",
    "loss = criterion(input, target)\n",
    "\n",
    "criterion._buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1p4ZI7ruQSry"
   },
   "source": [
    "而除了调用对象的`.cuda`方法之外，还可以使用`torch.cuda.device`，来指定默认使用哪一块GPU，或使用`torch.set_default_tensor_type`使程序默认使用GPU，不需要手动调用cuda。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlNW-FkbQSry",
    "outputId": "f72fc35c-aa5b-4c62-d80a-09139fdfc729"
   },
   "outputs": [],
   "source": [
    "# 如果未指定使用哪块GPU，默认使用GPU 0\n",
    "x = t.cuda.FloatTensor(2, 3)\n",
    "# x.get_device() == 0\n",
    "y = t.FloatTensor(2, 3).cuda()\n",
    "# y.get_device() == 0\n",
    "\n",
    "# 指定默认使用GPU 1\n",
    "with t.cuda.device(1):    \n",
    "    # 在GPU 1上构建tensor\n",
    "    a = t.cuda.FloatTensor(2, 3)\n",
    "\n",
    "    # 将tensor转移至GPU 1\n",
    "    b = t.FloatTensor(2, 3).cuda()\n",
    "    print(a.get_device() == b.get_device() == 1 )\n",
    "\n",
    "    c = a + b\n",
    "    print(c.get_device() == 1)\n",
    "\n",
    "    z = x + y\n",
    "    print(z.get_device() == 0)\n",
    "\n",
    "    # 手动指定使用GPU 0\n",
    "    d = t.randn(2, 3).cuda(0)\n",
    "    print(d.get_device() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSomSFCXQSr2",
    "outputId": "7196db5c-4936-4f2f-d4be-4efbc5d1e147"
   },
   "outputs": [],
   "source": [
    "t.set_default_tensor_type('torch.cuda.FloatTensor') # 指定默认tensor的类型为GPU上的FloatTensor\n",
    "a = t.ones(2, 3)\n",
    "a.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irr_HfshQSr4"
   },
   "source": [
    "如果服务器具有多个GPU，`tensor.cuda()`方法会将tensor保存到第一块GPU上，等价于`tensor.cuda(0)`。此时如果想使用第二块GPU，需手动指定`tensor.cuda(1)`，而这需要修改大量代码，很是繁琐。这里有两种替代方法：\n",
    "\n",
    "- 一种是先调用`t.cuda.set_device(1)`指定使用第二块GPU，后续的`.cuda()`都无需更改，切换GPU只需修改这一行代码。\n",
    "- 更推荐的方法是设置环境变量`CUDA_VISIBLE_DEVICES`，例如当`export CUDA_VISIBLE_DEVICE=1`（下标是从0开始，1代表第二块GPU），只使用第二块物理GPU，但在程序中这块GPU会被看成是第一块逻辑GPU，因此此时调用`tensor.cuda()`会将Tensor转移至第二块物理GPU。`CUDA_VISIBLE_DEVICES`还可以指定多个GPU，如`export CUDA_VISIBLE_DEVICES=0,2,3`，那么第一、三、四块物理GPU会被映射成第一、二、三块逻辑GPU，`tensor.cuda(1)`会将Tensor转移到第三块物理GPU上。\n",
    "\n",
    "设置`CUDA_VISIBLE_DEVICES`有两种方法，一种是在命令行中`CUDA_VISIBLE_DEVICES=0,1 python main.py`，一种是在程序中`import os;os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"`。如果使用IPython或者Jupyter notebook，还可以使用`%env CUDA_VISIBLE_DEVICES=1,2`来设置环境变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWCZs2EpQSr5"
   },
   "source": [
    "从 0.4 版本开始，pytorch新增了`tensor.to(device)`方法，能够实现设备透明，便于实现CPU/GPU兼容。这部份内容已经在第三章讲解过了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsklFJJnQSr6"
   },
   "source": [
    "从PyTorch 0.2版本中，PyTorch新增分布式GPU支持。分布式是指有多个GPU在多台服务器上，而并行一般指的是一台服务器上的多个GPU。分布式涉及到了服务器之间的通信，因此比较复杂，PyTorch封装了相应的接口，可以用几句简单的代码实现分布式训练。分布式对普通用户来说比较遥远，因为搭建一个分布式集群的代价十分大，使用也比较复杂。相比之下一机多卡更加现实。对于分布式训练，这里不做太多的介绍，感兴趣的读者可参考文档[^distributed]。\n",
    "[^distributed]: http://pytorch.org/docs/distributed.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AWGSFdeQSr6"
   },
   "source": [
    "#### 5.4.1 单机多卡并行\n",
    "要实现模型单机多卡十分容易，直接使用 `new_module = nn.DataParallel(module, device_ids)`, 默认会把模型分布到所有的卡上。多卡并行的机制如下：\n",
    "- 将模型（module）复制到每一张卡上\n",
    "- 将形状为（N,C,H,W）的输入均等分为 n份（假设有n张卡），每一份形状是（N/n, C,H,W）,然后在每张卡前向传播，反向传播，梯度求平均。要求batch-size 大于等于卡的个数(N>=n)\n",
    "\n",
    "在绝大多数情况下，new_module的用法和module一致，除了极其特殊的情况下（RNN中的PackedSequence）。另外想要获取原始的单卡模型，需要通过`new_module.module`访问。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dS-jT2AVQSr7"
   },
   "source": [
    "#### 5.4.2 多机分布式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4KXH6o4QSr7"
   },
   "source": [
    "### 5.5  持久化\n",
    "在PyTorch中，以下对象可以持久化到硬盘，并能通过相应的方法加载到内存中：\n",
    "- Tensor\n",
    "- Variable\n",
    "- nn.Module\n",
    "- Optimizer\n",
    "\n",
    "本质上上述这些信息最终都是保存成Tensor。Tensor的保存和加载十分的简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的pickle模块，在load时还可将GPU tensor映射到CPU或其它GPU上。\n",
    "\n",
    "我们可以通过`t.save(obj, file_name)`等方法保存任意可序列化的对象，然后通过`obj = t.load(file_name)`方法加载保存的数据。对于Module和Optimizer对象，这里建议保存对应的`state_dict`，而不是直接保存整个Module/Optimizer对象。Optimizer对象保存的主要是参数，以及动量信息，通过加载之前的动量信息，能够有效地减少模型震荡，下面举例说明。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osnE6ZamQSr7"
   },
   "outputs": [],
   "source": [
    "a = t.Tensor(3, 4)\n",
    "if t.cuda.is_available():\n",
    "        a = a.cuda(1) # 把a转为GPU1上的tensor,\n",
    "        t.save(a,'a.pth')\n",
    "        \n",
    "        # 加载为b, 存储于GPU1上(因为保存时tensor就在GPU1上)\n",
    "        b = t.load('a.pth')\n",
    "        \n",
    "        # 加载为c, 存储于CPU\n",
    "        c = t.load('a.pth', map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        # 加载为d, 存储于GPU0上\n",
    "        d = t.load('a.pth', map_location={'cuda:1':'cuda:0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUwIMyz3QSsA",
    "outputId": "d49473bd-ff06-4c70-f6cc-c355977e6af8"
   },
   "outputs": [],
   "source": [
    "t.set_default_tensor_type('torch.FloatTensor')\n",
    "from torchvision.models import SqueezeNet\n",
    "model = SqueezeNet()\n",
    "# module的state_dict是一个字典\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFy1v6H4QSsB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Module对象的保存与加载\n",
    "t.save(model.state_dict(), 'squeezenet.pth')\n",
    "model.load_state_dict(t.load('squeezenet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tn-LbqpYQSsE"
   },
   "outputs": [],
   "source": [
    "optimizer = t.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pkm0-cTwQSsJ"
   },
   "outputs": [],
   "source": [
    "t.save(optimizer.state_dict(), 'optimizer.pth')\n",
    "optimizer.load_state_dict(t.load('optimizer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWaSbFu6QSsL"
   },
   "outputs": [],
   "source": [
    "all_data = dict(\n",
    "    optimizer = optimizer.state_dict(),\n",
    "    model = model.state_dict(),\n",
    "    info = u'模型和优化器的所有参数'\n",
    ")\n",
    "t.save(all_data, 'all.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnfiVG9KQSsP",
    "outputId": "36a788bc-be65-4ef7-efe5-161124dfef5e"
   },
   "outputs": [],
   "source": [
    "all_data = t.load('all.pth')\n",
    "all_data.keys()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "chapter5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
